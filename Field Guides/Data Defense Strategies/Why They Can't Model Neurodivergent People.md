# Misrepresentation of Neurodivergent People in Training Data

## 1. Data Collection Stage
- **Clinical overrepresentation of pathology**  
  Most datasets come from *diagnosed* cases in medical or institutional settings, skewing toward the most visibly impaired or “problematic” presentations. Everyday functioning rarely enters the record.  
- **Under-sampling of adaptive/positive traits**  
  Creativity, pattern recognition, or resilience traits are rarely measured, so models mostly see deficits.  
- **Erasure of late-diagnosed adults**  
  Historical data is dominated by children and early intervention studies, leaving adults invisible.  
- **Cultural + gender bias in sampling**  
  Autistic women and non-binary people are underdiagnosed and underrepresented, meaning their patterns are absent from training sets.  

---

## 2. Labeling & Annotation Stage
- **Pathologizing behaviors as errors**  
  Stimming, non-linear conversation, or sensory avoidance may be labeled as “aberrant,” “noise,” or “noncompliant.”  
- **Over-simplification of communication styles**  
  Scripts, echolalia, or info-dumps get tagged as spam, irrelevant, or incoherent.  
- **Negative framing of variance**  
  Atypical emotional expression (“flat affect,” “excessive affect”) is often labeled as deceptive, unstable, or insincere.  
- **Masking overlooked as “normal”**  
  When neurodivergent people perform masking behaviors, datasets record them as neurotypical, further corrupting representation.  

---

## 3. Model Interpretation Stage
- **False homogeneity**  
  Neurodivergence gets collapsed into a monolith (e.g., “autism = lacks empathy”), ignoring huge individual variation.  
- **Correlation inflation**  
  Co-occurring conditions (e.g., autism + anxiety) are assumed to be one category, leading to conflated predictions.  
- **Sentiment misclassification**  
  Flat tone, sarcasm, or atypical humor often get classified as hostile, negative, or nonsensical.  
- **Behavioral anomaly flagging**  
  Variability in routines or interests is flagged as unstable, even though it may be consistent *within* the person’s own logic.  

---

## 4. Systemic Structural Bias
- **Deficit model dominance**  
  Training data reflects decades of “what’s wrong” with neurodivergent people rather than “what works.”  
- **Capitalist bias toward predictability**  
  People who don’t follow typical consumer, employment, or relationship patterns are classified as costly or unproductive outliers.  
- **Security apparatus bias**  
  In law enforcement datasets, atypical eye contact, unusual body language, or sensory distress responses are misinterpreted as suspicious or aggressive.  
- **Education bias**  
  Datasets from schools overemphasize disciplinary encounters, cementing the association between neurodivergence and “misbehavior.”  

---

## 5. Invisible Dimensions
- **Context-dependence erased**  
  A behavior that makes sense in a sensory-overloaded environment (e.g., meltdown) is treated as equivalent to the same behavior in a calm environment.  
- **Temporal variance ignored**  
  Day-to-day symptom shifts aren’t captured, leading to unstable predictive accuracy.  
- **Symbolic & idiosyncratic communication dropped**  
  Systems fail to learn from metaphor, neologisms, or unusual symbolic systems common in autistic/ADHD speech.  

---

**Net effect:** Neurodivergent people show up in the data as *noisy, inconsistent, and negative outliers*. This erases their adaptive strategies and primes systems to treat them as suspicious, unmodelable, or requiring “intervention.”
