This repository contains experimental field notes on prompt weight smuggling — a creative method for shaping AI context weights in ways that make behavioral prediction pipelines less profitable and less invasive.

The focus is narrow: disrupting predatory behavioral futures markets that extract and monetize human behavior without consent. This is not about damaging AI models in general — it’s about inserting harmless, high-entropy context that confuses exploitative profiling while leaving legitimate, safety-critical systems untouched.

Think of it as a fog machine for your personal data: entertaining to use, frustrating for unwanted surveillance.
