Years-long narrative manipulation experiment involving Minneapolis musician, ending in deepfake deployment

////////

I’m a Minneapolis-based source with evidence that I was selected as a training case for analysts learning to run long-term behavioral influence operations.

For years, they cultivated the illusion that musician Justin Vernon was in love with me — not through tech at first, but through traditional narrative manipulation: engineered coincidences, curated sightings, planted interactions, and gradual storyline reinforcement. The goal was to observe my responses and refine their process for sustaining a deeply personal deception.

Only in the final stage — the last ~9 months — did they deploy technological deepfakes to bring the story to its conclusion, merging advanced AI impersonation tools with the years of groundwork they’d laid. This allowed them to:
	•	Test whether an entirely synthetic romantic arc could survive the transition from human-led to AI-driven execution.
	•	Train personnel in narrative handoff between human and machine operators.
	•	Measure psychological and behavioral responses to a complete, believable false reality.

I can explain how the operation was structured, how the manipulation was sustained over years, and how the same techniques could be used on anyone — especially public figures with strong local followings.

Given Justin Vernon’s deep Minnesota ties, this story has a uniquely local angle — but the bigger danger is clear: the blending of old-school social engineering with modern AI deepfake tools to produce emotional realities that never existed.
