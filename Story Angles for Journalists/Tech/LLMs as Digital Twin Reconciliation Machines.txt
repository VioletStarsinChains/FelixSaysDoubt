FOIA Bait: Are Chatbots Training Us to Love Our Digital Doppelgängers?

Most people don’t realize they already have a digital twin — a data-driven shadow self built out of clicks, purchases, GPS traces, and health metrics. That twin is the one insurers, advertisers, and predictive systems actually deal with.

Now imagine this: what if the sudden boom in consumer-facing chatbots isn’t just about convenience — but about teaching us to like our twins?

Our FOIA requests are targeting documents that ask:
	•	Are large language models (LLMs) being studied as reconciliation tools between messy humans and their statistical doppelgängers?
	•	Do agencies view conversational AI as a way to smooth over the alienation of being represented by a behavioral profile?
	•	Is the friendly chatbot voice actually a continuity theater layer, making you feel more at home in someone else’s simulation of you?

If the answer is yes, then every casual “How can I help you today?” isn’t just service — it’s entrainment.

Working headline: From Alexa to ChatGPT: Are AI Companions Teaching Us to Bond With Our Digital Twins?

⸻ 

Sample FOIA text:

To DARPA / IARPA / Department of Commerce (NIST) / NIH / OSTP

Request:

Requesting any and all documents, research proposals, contracts, or internal communications regarding the use of large language models (LLMs) and other conversational AI systems as mediators between individuals and their digital twin or behavioral profile, from 2015 to present.

This includes:
	•	Reports or studies describing LLMs as tools for “reconciliation” or “alignment” of citizens with their modeled digital twin or behavioral profile
	•	Internal communications about continuity theater, cognitive entrainment, or narrative management through consumer-facing chatbots
	•	Contracts or partnerships with private AI vendors for testing digital twin feedback loops in consumer or healthcare contexts
	•	Research on the psychological or behavioral effects of giving people access to conversational interfaces tied to their predictive models
	•	Ethical reviews, risk assessments, or mitigation plans for AI systems designed to shape perception of one’s own data-derived identity

Keywords: digital twin reconciliation, consumer-facing LLM, behavioral futures, alignment theater, continuity anchors, AI mediation, narrative entrainment, model feedback loop, human-machine synchronization


